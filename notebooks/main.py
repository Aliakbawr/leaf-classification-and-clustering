# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n7ei9NMr7r7CR7948nMUnMIVVttUZYSv

#Classification
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from sklearn.linear_model  import LogisticRegression

import os
import cv2
from skimage.feature import greycomatrix, greycoprops
from skimage import io, color

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, v_measure_score, homogeneity_score, completeness_score, silhouette_score
from sklearn.manifold import TSNE
from scipy import stats

file_path = '/content/drive/My Drive/programming/leaf-classification-clustering/data/leaves.csv'
df = pd.read_csv(file_path, header=None)
column_names = [f'feature_{i}' for i in range(df.shape[1])]
df.columns = column_names

print(df.head())
print(df.shape)

df.describe()  # Get summary statistics

root_folder = '/content/drive/My Drive/programming/leaf-classification-clustering/data/leaves'

unique_classes = df['feature_0'].unique()

def load_images(root_folder, df):
    images = []
    for index, row in df.iterrows():
        class_number = int(row['feature_0'])
        image_number = int(row['feature_1'])
        image_name = f"iPAD2_C{class_number:02d}_EX{image_number:02d}.JPG"
        class_folder = os.path.join(root_folder, f"{class_number}. {row['class_Name']}")
        image_path = os.path.join(class_folder, image_name)
        if os.path.exists(image_path):
            image = io.imread(image_path)
            image = color.rgb2gray(image)
            images.append(image)
        else:
            images.append(None)  # Handle missing images appropriately
    return images

class_name_mapping = {
    1: "Quercus suber",
    2: "Salix atrocinerea",
    3: "Populus nigra",
    4: "Alnus sp",
    5: "Quercus robur",
    6: "Crataegus monogyna",
    7: "Ilex aquifolium",
    8: "Nerium oleander",
    9: "Betula pubescens",
    10: "Tilia tomentosa",
    11: "Acer palmaturu",
    12: "Celtis sp",
    13: "Corylus avellana",
    14: "Castanea sativa",
    15: "Populus alba",
    22: "Primula vulgaris",
    23: "Erodium sp",
    24: "Bougainvillea sp",
    25: "Arisarum vulgare",
    26: "Euonymus japonicus",
    27: "Ilex perado ssp azorica",
    28: "Magnolia soulangeana",
    29: "Buxus sempervirens",
    30: "Urtica dioica",
    31: "Podocarpus sp",
    32: "Acca sellowiana",
    33: "Hydrangea sp",
    34: "Pseudosasa japonica",
    35: "Magnolia grandiflora",
    36: "Geranium sp"
}
df['class_Name'] = df['feature_0'].map(class_name_mapping)
# Load the images
images = load_images(root_folder, df)

def extract_texture_features(image):
    if image.dtype == np.float64:
        image = (image * 255).astype(np.uint8)
    # Compute GLCM
    glcm = greycomatrix(image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)

    # Compute texture features
    contrast = greycoprops(glcm, prop='contrast')[0, 0]
    dissimilarity = greycoprops(glcm, prop='dissimilarity')[0, 0]
    homogeneity = greycoprops(glcm, prop='homogeneity')[0, 0]
    energy = greycoprops(glcm, prop='energy')[0, 0]
    correlation = greycoprops(glcm, prop='correlation')[0, 0]

    return [contrast, dissimilarity, homogeneity, energy, correlation]

# Extract texture features for all images
texture_features = []
for image in images:
    if image is not None:
        features = extract_texture_features(image)
        texture_features.append(features)
    else:
        texture_features.append([np.nan] * 5)  # Handle missing images appropriately

texture_features_df = pd.DataFrame(texture_features, columns=['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'])

texture_features_df.describe()

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from sklearn.linear_model  import LogisticRegression

# Concatenate the original dataset with the new texture features
df_combined = pd.concat([df, texture_features_df], axis=1)

# Split the data into features and target
X = df_combined.drop(columns=['feature_0','feature_1','class_Name'])
y = df_combined['feature_0']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)

clf = Pipeline([
  ('feature_selection', SelectFromModel(estimator=LogisticRegression())),
  ('classification', ExtraTreesClassifier(n_estimators=65, random_state=43))
])
clf.fit(X_train, y_train)

# Predictions and evaluation
y_pred = clf.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')

print(classification_report(y_test, y_pred))

print('Confusion Matrix:')
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""#Clustering"""

# Standardizing the features
scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)

# Clip outliers
X_scaled = np.clip(X_scaled, -3, 3)


# Applying PCA
pca = PCA(n_components=11)
X_pca = pca.fit_transform(X_scaled)

agglo = AgglomerativeClustering(n_clusters=30)
agglo_labels = agglo.fit_predict(X_pca)

# Evaluate Agglomerative Clustering
homogeneity_agglo = homogeneity_score(y, agglo_labels)
completeness_agglo = completeness_score(y, agglo_labels)
v_measure_agglo = v_measure_score(y, agglo_labels)
ari_agglo = adjusted_rand_score(y, agglo_labels)
nmi_agglo = normalized_mutual_info_score(y, agglo_labels)
silhouette_avg = silhouette_score(X_pca, agglo_labels)

print(f'Silhouette Score: {silhouette_avg}')
print(f'Agglomerative Clustering Homogeneity: {homogeneity_agglo:.2f}')
print(f'Agglomerative Clustering Completeness: {completeness_agglo:.2f}')
print(f'Agglomerative Clustering V-measure: {v_measure_agglo:.2f}')
print(f'Agglomerative Clustering Adjusted Rand Index: {ari_agglo:.2f}')
print(f'Agglomerative Clustering Normalized Mutual Information: {nmi_agglo:.2f}')

"""# Clusters and Classes relation"""

# Visualize the clusters and true classes using t-SNE
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_scaled)

plt.figure(figsize=(10, 6))
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=agglo_labels, cmap='viridis', s=50, alpha=0.7, label='Clusters')
plt.title('t-SNE Visualization of Clusters')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis', s=50, alpha=0.7, label='True Classes')
plt.title('t-SNE Visualization of True Classes')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.legend()
plt.show()